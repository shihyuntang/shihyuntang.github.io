<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.3">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shih-Yun Tang">

  
  
  
    
  
  <meta name="description" content="Clustering and classification are fundamental techniques in data analysis and machine learning, used to group data points based on similarities and to categorize them into distinct classes.
Hierarchical Clustering Hierarchical clustering builds nested clusters by progressively merging or splitting them based on the distance between data points or groups. The method relies heavily on the choice of distance calculation:
Single Linkage (Nearest Neighbor): This method, also known as the friend-of-a-friend technique, considers the shortest distance between points in two clusters (see the first plot below).">

  
  <link rel="alternate" hreflang="en-us" href="https://shihyuntang.github.io/tutorials/astro-stat/6-clustering-and-classification/">

  


  
  
  
  <meta name="theme-color" content="#ff704d">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light" disabled>
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark">
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cutive+Mono%7CLora:400,700%7CRoboto:400,700&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://shihyuntang.github.io/tutorials/astro-stat/6-clustering-and-classification/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Shih-Yun Tang">
  <meta property="og:url" content="https://shihyuntang.github.io/tutorials/astro-stat/6-clustering-and-classification/">
  <meta property="og:title" content="Clustering and Classification | Shih-Yun Tang">
  <meta property="og:description" content="Clustering and classification are fundamental techniques in data analysis and machine learning, used to group data points based on similarities and to categorize them into distinct classes.
Hierarchical Clustering Hierarchical clustering builds nested clusters by progressively merging or splitting them based on the distance between data points or groups. The method relies heavily on the choice of distance calculation:
Single Linkage (Nearest Neighbor): This method, also known as the friend-of-a-friend technique, considers the shortest distance between points in two clusters (see the first plot below)."><meta property="og:image" content="https://shihyuntang.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://shihyuntang.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-08-11T00:00:00&#43;01:00">
    
    <meta property="article:modified_time" content="2024-05-02T20:53:04-05:00">
  

  



  


  


  





  <title>Clustering and Classification | Shih-Yun Tang</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="dark">

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  

<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Shih-Yun Tang</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Shih-Yun Tang</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/tutorials/"><span>Tutorials and Notes</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/cv.pdf"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/">Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/1-1-some-basic/">1 Probability</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/1-1-some-basic/">Probability Basic</a>
      </li>
      
      <li >
        <a href="/tutorials/astro-stat/1-2-probability/">Distributions</a>
      </li>
      
      <li >
        <a href="/tutorials/astro-stat/1-3-bayesian/">Bayes&#39; theorem</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/2-1-distribution/">2 Nonparametric</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/2-1-distribution/">Distribution</a>
      </li>
      
      <li >
        <a href="/tutorials/astro-stat/2-2-correlation/">Correlation</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/3-1-data-smoothing/">3 Data Smoothing</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/3-1-data-smoothing/">Data Smoothing</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/4-1-regression/">4 Regression</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/4-1-regression/">Regression</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/5-1-multivariate-analysis/">5 Multivariate Analysis</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/5-1-multivariate-analysis/">Multivariate Analysis</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/6-clustering-and-classification/">6 Clustering and Classification</a>
    <ul class="nav docs-sidenav">
      
      <li class="active">
        <a href="/tutorials/astro-stat/6-clustering-and-classification/">Clustering and Classification</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/7-censored-and-truncated-data/">7 Censored and Truncated Data</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/7-censored-and-truncated-data/">Censored and Truncated Data</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/8-timeseries-analysis/">8 Timeseries Analysis</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/8-timeseries-analysis/">Timeseries Analysis</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/tutorials/astro-stat/9-1-variogram/">9 Spatial Point Processes</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/tutorials/astro-stat/9-1-variogram/">Variogram</a>
      </li>
      
      <li >
        <a href="/tutorials/astro-stat/9-2-kriging/">Kriging</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#hierarchical-clustering">Hierarchical Clustering</a></li>
        <li><a href="#k-means-clustering">k-Means Clustering</a></li>
        <li><a href="#density-based-spatial-clustering-of-applications-with-noise-dbscan">Density-Based Spatial Clustering of Applications with Noise (DBSCAN)</a></li>
        <li><a href="#k-nearest-neighbor-k-nn">k-Nearest Neighbor (k-NN)</a></li>
      </ul>
    </li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          <h1>Clustering and Classification</h1>

          <div class="article-style">
            <p>Clustering and classification are fundamental techniques in data analysis and machine learning, used to group data points based on similarities and to categorize them into distinct classes.</p>
<h3 id="hierarchical-clustering">Hierarchical Clustering</h3>
<p>Hierarchical clustering builds nested clusters by progressively merging or splitting them based on the distance between data points or groups. The method relies heavily on the choice of distance calculation:</p>
<ul>
<li><strong>Single Linkage (Nearest Neighbor)</strong>: This method, also known as the friend-of-a-friend technique, considers the shortest distance between points in two clusters (see the first plot below). It can result in elongated, &ldquo;chain-like&rdquo; clusters that capture local structure but might miss broader data groupings (see the second plot below).</li>
<li><strong>Complete Linkage</strong>: Use the maximum distance between points in two clusters. This method tends to produce more compact and well-separated clusters, reducing the chain effect seen in single linkage.</li>
<li><strong>Average Linkage</strong>: Calculates the average distance between all pairs of points in two clusters. This method provides a balance between the sensitivity of single linkage and the strictness of complete linkage.</li>
<li><strong>Ward&rsquo;s Minimum Variance</strong>: Minimizes the total within-cluster variance. At each step, the pair of clusters with the minimum increase in total variance are merged. This method tends to create more regular-sized clusters (e.g., spherical or ellipsoidal), which can be advantageous for certain datasets.</li>
</ul>
<p><img src="https://www.researchgate.net/profile/Pamela-Guevara/publication/281014334/figure/fig57/AS:418517879934980@1476793847581/The-three-linkage-types-of-hierarchical-clustering-single-link-complete-link-and.png" alt="">
(Figure credit: <a href="https://www.researchgate.net/figure/The-three-linkage-types-of-hierarchical-clustering-single-link-complete-link-and_fig57_281014334">https://www.researchgate.net/figure/The-three-linkage-types-of-hierarchical-clustering-single-link-complete-link-and_fig57_281014334</a>)</p>
<p>Once distances are calculated, the hierarchical clustering algorithm uses these distances to merge or split clusters:</p>
<ol>
<li><strong>Initialization</strong>: Start by assigning each data point to its own cluster.</li>
<li><strong>Merge Step</strong>: At each step, merge the two clusters that are closest together, based on the distance calculation method chosen.</li>
<li><strong>Update Distances</strong>: Recalculate the distances between the new cluster and each of the old clusters.</li>
<li><strong>Repeat</strong>: Continue merging clusters until all data points are merged into a single cluster or until a desired number of clusters is reached.</li>
</ol>
<p>These different linkage criteria can significantly impact the shapes and sizes of the clusters formed. A nice demonstration in various clustering scenarios can be found on the scikit-learn page, also shown below:
<img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_linkage_comparison_001.png" alt="">
(Figure credit: <a href="https://scikit-learn.org/stable/auto_examples/cluster/plot_linkage_comparison.html#sphx-glr-auto-examples-cluster-plot-linkage-comparison-py">https://scikit-learn.org/stable/auto_examples/cluster/plot_linkage_comparison.html#sphx-glr-auto-examples-cluster-plot-linkage-comparison-py</a>)</p>
<h3 id="k-means-clustering">k-Means Clustering</h3>
<p>k-Means clustering partitions the data into $k$ mutually exclusive clusters, and returns the index of the cluster each point belongs to. This method aims to minimize the within-cluster sum of squares.</p>
<h3 id="density-based-spatial-clustering-of-applications-with-noise-dbscan">Density-Based Spatial Clustering of Applications with Noise (DBSCAN)</h3>
<p>DBSCAN groups together closely packed points and marks points in low-density regions as outliers. This method does not require specifying the number of clusters a priori, making it suitable for data with irregular or complex structures.</p>
<ul>
<li><strong>Parameters</strong>:
<ul>
<li>$\mu$: Minimum number of points required to form a dense region.</li>
<li>$\varepsilon$: Specifies the &ldquo;reach&rdquo;, that is, the distance threshold within which points are considered neighbors.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="k-nearest-neighbor-k-nn">k-Nearest Neighbor (k-NN)</h3>
<p>k-Nearest Neighbors (k-NN) is primarily a classification technique renowned for its simplicity and effectiveness, especially suited for datasets where the decision boundaries between classes are not linear. The k-NN algorithm classifies new data points based on the majority vote of their k nearest neighbors in the feature space.</p>
<p>To apply k-NN effectively, data is typically split into two sets:</p>
<ul>
<li><strong>Training Set</strong>: This dataset is used to &rsquo;train&rsquo; or &lsquo;fit&rsquo; the model. It includes both the input features and the corresponding classification labels which are known.</li>
<li><strong>Test Set</strong>: This dataset is used solely for testing the performance of the trained model. It helps to evaluate how well the k-NN model generalizes to new, previously unseen data.</li>
</ul>
<p>Once the model has been trained on the training set, it can be used to predict the class labels of new data in the test set, providing a measure of its classification accuracy.</p>
<!-- ## Summary Table for Clustering and Classification Methods

| **Method**           | **Characteristics**                                       | **Best Used For**                                       |
|----------------------|-----------------------------------------------------------|---------------------------------------------------------|
| **Hierarchical Clustering** | Builds clusters based on various distance calculations between points. | Data with inherent hierarchical structure and when a visual representation of cluster formation is beneficial. |
| **k-Means Clustering**      | Partitions data into k predefined clusters by minimizing within-cluster variances. | Large datasets with well-separated clusters, where the number of clusters is known a priori. |
| **DBSCAN**                  | Groups densely packed points and identifies points in low-density areas as outliers. Does not require predefined cluster number. | Complex datasets with noise and irregular cluster shapes, not well-suited to global clustering criteria. |
| **k-Nearest Neighbors (k-NN)** | Classifies data based on the majority label among the nearest k neighbors. Utilizes training and test datasets to ensure model accuracy and generalization. | Classification tasks, especially in cases with non-linear decision boundaries and when model simplicity and interpretability are important. | -->

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/tutorials/astro-stat/5-1-multivariate-analysis/" rel="next">Multivariate Analysis</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/tutorials/astro-stat/7-censored-and-truncated-data/" rel="prev">Nondetections-Censored and Truncated Data</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on May 2, 2024</p>

          





  
  

<p class="edit-page">
  <a href="https://github.com/gcushen/hugo-academic/edit/master/content/tutorials/astro-stat/6%20Clustering%20and%20Classification.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>




          

        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    © 2018-2024 Shih-Yun Tang &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.3.1/mermaid.min.js" integrity="sha256-vOIuDSYDirTfyr+S2MjFnhOz6Rgiz4ODFAHATG0rFxw=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.dd460abf651c4e91377a0cc642a37eec.js"></script>

    






  
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
